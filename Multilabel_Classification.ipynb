{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X, _y = mnist[\"data\"], mnist[\"target\"]\n",
    "_y = _y.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = _X[:60000], _X[60000:], _y[:60000], _y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_large = (y_train >= 7)\n",
    "y_train_odd = (y_train % 2 == 1)\n",
    "y_train_multilabel = (np.c_[y_train_large, y_train_odd]).astype(np.uint8)\n",
    "\n",
    "y_test_large = (y_test >= 7)\n",
    "y_test_odd = (y_test % 2 == 1)\n",
    "y_test_multilabel = (np.c_[y_test_large, y_test_odd]).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W):\n",
    "    return np.round(sigmoid(X @ W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, T, W):\n",
    "    epsilon = 1e-5\n",
    "    N = len(T)\n",
    "    K = np.size(T, 1)\n",
    "    cost = - (1/N) * np.ones((1,N)) @ (np.multiply(np.log(sigmoid(X @ W) + epsilon), T)) @ np.ones((K,1)) + \\\n",
    "          (- (1/N) * np.ones((1,N)) @ (np.multiply(np.log(1 - sigmoid(X @ W) + epsilon), (1 - T))) @ np.ones((K,1)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gd(X, T, W, learning_rate, iterations, batch_size):\n",
    "    N = len(T)\n",
    "    cost_history = np.zeros((iterations,1))\n",
    "    shuffled_indices = np.random.permutation(N)\n",
    "    X_shuffled = X[shuffled_indices]\n",
    "    T_shuffled = T[shuffled_indices]\n",
    "\n",
    "    for i in range(iterations):\n",
    "        j = i % N\n",
    "        X_batch = X_shuffled[j:j+batch_size]\n",
    "        T_batch = T_shuffled[j:j+batch_size]\n",
    "        # batch가 epoch 경계를 넘어가는 경우, 앞 부분으로 채워줌\n",
    "        if X_batch.shape[0] < batch_size:\n",
    "            X_batch = np.vstack((X_batch, X_shuffled[:(batch_size - X_batch.shape[0])]))\n",
    "            T_batch = np.vstack((T_batch, T_shuffled[:(batch_size - T_batch.shape[0])]))\n",
    "        W = W - (learning_rate/batch_size) * (X_batch.T @ (sigmoid(X_batch @ W) - T_batch))\n",
    "        cost_history[i] = compute_cost(X_batch, T_batch, W)\n",
    "        if i % 10 == 0:\n",
    "            print(cost_history[i][0])\n",
    "\n",
    "    return (cost_history, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cost is: 1.386254361519962 \n",
      "\n",
      "1.371562344118162\n",
      "1.2443026797808128\n",
      "1.12087734641946\n",
      "0.9130497710356509\n",
      "0.9525008778287885\n",
      "1.0455213553853304\n",
      "0.9271487813319529\n",
      "0.7610318533451474\n",
      "0.7214337094981859\n",
      "0.7370809970719829\n",
      "0.7612369147418179\n",
      "0.8425573965769991\n",
      "0.8276409345842012\n",
      "0.8715756355788393\n",
      "0.903016275266288\n",
      "0.9005939492607414\n",
      "0.9502275800250233\n",
      "0.8629534378467929\n",
      "0.8631589342070811\n",
      "0.8537932508100096\n",
      "0.814319069426589\n",
      "0.7299088312182276\n",
      "0.7381904286470109\n",
      "0.8443522772476361\n",
      "0.9629685323712587\n",
      "0.8747018639794758\n",
      "1.0841284094068342\n",
      "0.8156068779844285\n",
      "0.8601381822644083\n",
      "0.8743313614760715\n",
      "0.8600976847871312\n",
      "0.753522352266142\n",
      "0.7875417568434826\n",
      "0.6547383086141267\n",
      "0.6775649937105073\n",
      "0.6932264197153619\n",
      "0.650004035335418\n",
      "0.6292532200312051\n",
      "0.7543904875061268\n",
      "0.746159376496436\n",
      "0.6239647264205174\n",
      "0.544686470710119\n",
      "0.4450078732719553\n",
      "0.6313497480214934\n",
      "0.685702022483454\n",
      "0.6684816211968114\n",
      "0.6571717321046839\n",
      "0.6239414252970119\n",
      "0.7075690110749082\n",
      "0.7842679822312991\n",
      "0.915852514800968\n",
      "1.0158209567715162\n",
      "1.014504831365394\n",
      "0.861005029525503\n",
      "0.7069351155879448\n",
      "0.6004922904930228\n",
      "0.7288942685331362\n",
      "0.6974014511274043\n",
      "0.7494487308970555\n",
      "0.6966337168744663\n",
      "0.7405650340816274\n",
      "0.7182838544360368\n",
      "0.6073402655539248\n",
      "0.6305386276609353\n",
      "0.6302692177293201\n",
      "0.5011505236408575\n",
      "0.5759683877252106\n",
      "0.7805248206561863\n",
      "0.6476786634577867\n",
      "0.5627786431760713\n",
      "0.6769720681325428\n",
      "0.7794278081448387\n",
      "0.6633510864989529\n",
      "0.7498875320119163\n",
      "0.7067120432119178\n",
      "0.7279538800560803\n",
      "0.7856931850008657\n",
      "0.5957503405655853\n",
      "0.5516273064804142\n",
      "0.6392220510415331\n",
      "0.6749202658362583\n",
      "0.7341025931798961\n",
      "0.698185706105475\n",
      "0.6635255283455883\n",
      "0.6411705591260968\n",
      "0.6321682026256998\n",
      "0.6280712261601852\n",
      "0.9144707864660616\n",
      "0.9598225927637285\n",
      "0.610329593374201\n",
      "0.5113238267045391\n",
      "0.6978117835663481\n",
      "0.5757284741740704\n",
      "0.5536809767672599\n",
      "0.5139265459785178\n",
      "0.5586099298701495\n",
      "0.6313404801871809\n",
      "0.5729083978841022\n",
      "0.5684909212545436\n",
      "0.5141366977905909\n",
      "0.5067165386192909\n",
      "0.622208043350124\n",
      "0.6472021115497438\n",
      "0.5342567443938755\n",
      "0.5628805319904131\n",
      "0.8111939586401951\n",
      "0.8289821481617294\n",
      "0.5647577192438511\n",
      "0.6179812052569276\n",
      "0.5286655353709477\n",
      "0.5446252387999273\n",
      "0.5046949890391532\n",
      "0.4681275042615685\n",
      "0.4669021887879782\n",
      "0.5136136720056145\n",
      "0.6127637835681212\n",
      "0.6455666362224184\n",
      "0.5517713665456656\n",
      "0.6057329936112731\n",
      "0.5789190575600032\n",
      "0.4762110673413822\n",
      "0.5672209625466966\n",
      "0.6004207498049519\n",
      "0.6592963429675194\n",
      "0.5740545293028391\n",
      "0.7233455285730392\n",
      "0.7996770590332758\n",
      "0.7650860858612429\n",
      "0.502375300742963\n",
      "0.41886267341041317\n",
      "0.5724439019682588\n",
      "0.5780947386033801\n",
      "0.5901569164607952\n",
      "0.6393438106469754\n",
      "0.5830914130590126\n",
      "0.6187676414186338\n",
      "0.5504785225103592\n",
      "0.6517686385779271\n",
      "0.7671768322328729\n",
      "0.6096936805190516\n",
      "0.6345357736157109\n",
      "0.6570187863808441\n",
      "0.5786689920093768\n",
      "0.4593648976998217\n",
      "0.560027496285709\n",
      "0.6425988202707609\n",
      "0.6076580976930991\n",
      "0.49702730267240025\n",
      "0.6301699882707806\n",
      "0.5892938424231784\n",
      "0.461672543508859\n",
      "0.4692883149351801\n",
      "0.3899270379553498\n",
      "0.3692352828647346\n",
      "0.5082481787841753\n",
      "0.4015671688406166\n",
      "0.5718972509024407\n",
      "0.7941092937482054\n",
      "0.6653505361017246\n",
      "0.5958652237790163\n",
      "0.43309425435226334\n",
      "0.48312632015038925\n",
      "0.5692701013045003\n",
      "0.5550362735014397\n",
      "0.6601567982685623\n",
      "0.8032494861849881\n",
      "1.0325321356852004\n",
      "0.6812163503761414\n",
      "0.4915082902048424\n",
      "0.4475210302310706\n",
      "0.41877814167941485\n",
      "0.3884590494394995\n",
      "0.42219052947793306\n",
      "0.5041891203131916\n",
      "0.4077644219666084\n",
      "0.34541592619969413\n",
      "0.45349708304211994\n",
      "0.4740622388466215\n",
      "0.738783688844274\n",
      "0.6970610758751636\n",
      "0.7100453139673872\n",
      "0.6886641375116995\n",
      "0.5347579247289105\n",
      "0.47379039655487903\n",
      "0.4539486086470921\n",
      "0.692339558702858\n",
      "0.7647976323383641\n",
      "0.670579438945331\n",
      "0.5853881056858631\n",
      "0.7074535231596694\n",
      "0.739839159856574\n",
      "0.5932275527393511\n",
      "0.38295039871971914\n",
      "0.8867105587663933\n",
      "0.9873075751183876\n",
      "0.9062632274593033\n",
      "0.8270907091038056\n",
      "0.5924115676751533\n",
      "0.6223170569767601\n",
      "0.59493144357521\n"
     ]
    }
   ],
   "source": [
    "X = np.hstack((np.ones((np.size(X_train, 0),1)),X_train))\n",
    "T = y_train_multilabel\n",
    "\n",
    "K = np.size(T, 1)\n",
    "M = np.size(X, 1)\n",
    "W = np.zeros((M,K))\n",
    "\n",
    "iterations = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "initial_cost = compute_cost(X, T, W)\n",
    "print(\"Initial Cost is: {} \\n\".format(initial_cost[0][0]))\n",
    "\n",
    "(cost_history, W_optimal) = batch_gd(X, T, W, learning_rate, iterations, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8852 0.8643]\n"
     ]
    }
   ],
   "source": [
    "## Accuracy: 각각의 클래스에 대한 정확도를 구하는 방식으로 측정하는 코드임\n",
    "X_ = np.hstack((np.ones((np.size(X_test, 0),1)),X_test))\n",
    "y_pred = predict(X_, W_optimal)\n",
    "score = sum(y_pred == y_test_multilabel)/ len(y_test_multilabel)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
