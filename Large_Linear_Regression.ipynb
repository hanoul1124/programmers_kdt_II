{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "\n",
    "# scikit learn의 LinearRegression 모델을 사용한 선형회귀 풀이\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000 # 데이터의 수. M, N은 매우 커지는 상황을 가정할 것임\n",
    "M = 3 # feature 수\n",
    "rng = np.random.RandomState(1)\n",
    "rng.rand(N, M).shape\n",
    "X = 10 * rng.rand(N, M)\n",
    "# [1.5, -2, 1] : Weight W를 임의로 이렇게 설정한 것.\n",
    "# 해당 weight에 input data X를 행렬곱한 것이 정답 label이 된다\n",
    "# 그리고 model은 계수를 학습하여 우리가 설정한 W에 가깝게 근사시킨 값을 리턴하면 된다\n",
    "np.dot(X, [1.5, -2., 1.]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.499999999999968\n",
      "[ 1.5 -2.   1. ]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "X = 10 * rng.rand(N, M)\n",
    "y = 0.5 + np.dot(X, [1.5, -2., 1.])\n",
    "\n",
    "model.fit(X, y)\n",
    "print(model.intercept_)\n",
    "# 우리가 설정했던 W 계수와 일치하는 계수값을 가지도록 학습되었음을 알 수 있다\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal equation 식을 직접 작성하여 선형회귀를 풀이하는 방식\n",
    "import numpy.linalg as LA\n",
    "normal_equation_solution = LA.inv(X.T@X)@X.T@y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.52825484, -1.96886193,  1.03058857])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위와는 bias 정도의 차이가 발생한듯?\n",
    "normal_equation_solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Memory Normal Equations (Online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대규모의 데이터를 가정한 경우의 학습방식.\n",
    "# 위에서는 한번에 X를 행렬 곱해버림. 그러나 대규모의 데이터로 메모리에 무리가 갈 수준의 큰 데이터라면\n",
    "# 위처럼 한 번에 X.T @ X 이런 식의 연산이 불가능함.\n",
    "# 따라서 위의 행렬식을 input data X행렬의 i번째 행(열)벡터 간 외적의 합으로 변형하여 점진적 online 학습이 진행되도록 만들어준다. \n",
    "A = np.zeros([M, M])\n",
    "b = np.zeros([M, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    A = A + X[i, np.newaxis].T@X[i, np.newaxis]\n",
    "    b = b + X[i, np.newaxis].T*y[i]\n",
    "solution = LA.inv(A)@b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.52825484],\n",
       "       [-1.96886193],\n",
       "       [ 1.03058857]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stochastic gradient descent\n",
    "w = np.zeros([M, 1]) # W값을 0으로 초기화, M개의 dimension(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.001 # Learning Rate\n",
    "n_iter = 1000 # 파라미터를 몇 번 업데이트 할 것인가 = 위에서 데이터의 수가 1000개이므로 1000번으로 설정했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.5271529 ]\n",
      " [-1.97170249]\n",
      " [ 1.0336901 ]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_iter):\n",
    "    i = i % N # i가 데이터의 수를 넘어가게 될 경우에 다시 처음부터\n",
    "    neg_gradient = (y[i] - w.T@X[i, np.newaxis].T) * X[i, np.newaxis].T\n",
    "    w = w + eta * neg_gradient\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
